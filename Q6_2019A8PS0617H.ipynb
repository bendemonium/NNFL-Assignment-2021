{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQHIyL0t8167"
      },
      "source": [
        "# **Q6**\n",
        "Implement multiclass LOR, multiclass LOR with L2-norm regularization, and\n",
        "multiclass LOR with L1-norm regularization models using BGD, SGD, and MBGD\n",
        "algorithms. The multiclass extension of the LOR models must be done using One vs.\n",
        "one and one vs. All coding algorithms. The dataset in data_q6_q7.txt contains 7\n",
        "features and one output. The output is classified as class 1, class2, or class 3. You\n",
        "must use hold-out cross-validation ((CV) with 70% as training, 10% as validation and\n",
        "20% as testing) for the evaluation of training, validation, and testing instances for each\n",
        "model. Evaluate the performance of each model using individual accuracy and overall\n",
        "accuracy measures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvjgotmP_06v"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl1aFLsoM65Y",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "385d24c5-5894-4e62-a322-36f7c3374a4e"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a88c5c2-c7a0-45f9-8cd1-33fb4196fcd9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a88c5c2-c7a0-45f9-8cd1-33fb4196fcd9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_q6_q7.txt to data_q6_q7.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h56m8LUsxd9E"
      },
      "source": [
        "def hyp(x,w):\n",
        "  return np.dot(x,w)\n",
        "def hyp_lor(x,w):\n",
        "  return 1/(1+np.exp(-(hyp(x,w))))\n",
        "def mse(y,pred,l):\n",
        "  return (1/l)*np.sum(np.square(y-pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JMkg2rGAUde"
      },
      "source": [
        "f,tr,va,te=8,147,21,42\n",
        "data=pd.read_csv(\"/content/data_q6_q7.txt\", delimiter = \"\\t\", header=None)\n",
        "data=pd.DataFrame(data)\n",
        "data.columns=['a','b','c','d','e','f','g','class_name']\n",
        "data.insert(0,\"x0\",1)\n",
        "data.insert(f,\"class_1\",0);data.insert(f+1,\"class_2\",0);data.insert(f+2,\"class_3\",0)\n",
        "dbool1,dbool2,dbool3 = (data.class_name==1),(data.class_name==2),(data.class_name==3)\n",
        "data.loc[dbool1,'class_1'],data.loc[dbool2,'class_2'],data.loc[dbool3,'class_3'] = 1,1,1\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JxnwsRWUPCD"
      },
      "source": [
        "# one vs all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9flsa-Rw58Ft"
      },
      "source": [
        "data=np.array(data); np.random.shuffle(data);np.random.shuffle(data)\n",
        "# so far : boolean added for binary class; data shuffled\n",
        "data_tr = data[:147,:-1].copy()\n",
        "data_va = data[147:168,:-1].copy()\n",
        "data_te = data[168:,:].copy()\n",
        "norm = np.amax(np.abs(data_tr),axis=0)\n",
        "data_tr,data_va,data_te_nor = data_tr/norm,data_va/norm,data_te[:,:-1]/norm #data normalised\n",
        "# so far 2 : data split\n",
        "x_test,y_test = data_te_nor[:,:f],data_te[:,f+3].reshape(te,1)\n",
        "x_valid,y_valid = data_va[:,:f],data_va[:,f].reshape(va,1)\n",
        "x_train = data_tr[:,:f]\n",
        "\n",
        "y1_train = data_tr[:,f].reshape(tr,1)\n",
        "y2_train = data_tr[:,f+1].reshape(tr,1)\n",
        "y3_train = data_tr[:,f+2].reshape(tr,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8bU31aJmYcp"
      },
      "source": [
        "## BGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2QJvG2kmbS6"
      },
      "source": [
        "### LoR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn-YSchsm00M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d54f9f-8b06-4968-9152-e031c2fd5836"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w1)-y1_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w1[j] = w1[j] - (1/tr)*2*jsum\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w2)-y2_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w2[j] = w2[j] - (1/tr)*0.2*jsum\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w3)-y3_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w3[j] = w3[j] - (1/tr)*1*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.8125\n",
            "Class 2 Accuracy = 0.9\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PETOqzk1uTN"
      },
      "source": [
        "### LoR with L2 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWdUaWgA1uTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9be8ee-391d-4460-d0c0-e247f12a56ba"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w1)-y1_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w1[j] = (1-(0.001*1.25))*w1[j] - (1/tr)*1.25*jsum\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w2)-y2_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w2[j] = (1-(0.01*0.3))*w2[j] - (1/tr)*0.3*jsum\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w3)-y3_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w3[j] = (1-(0.01*0.3))*w3[j] - (1/tr)*0.3*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.8125\n",
            "Class 2 Accuracy = 0.9\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzBrToVWy2FQ"
      },
      "source": [
        "### LoR with L1 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvAhvdUmy2FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be944cd-4ef4-4a60-f35b-e4f79fdbdc55"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w1)-y1_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w1[j] = w1[j] - (1/tr)*0.1*jsum - ((0.1*0.05)/2)*np.sign(w1[j])\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w2)-y2_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w2[j] = w2[j] - (1/tr)*1*jsum - ((1*0.005)/2)*np.sign(w2[j])\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x_train,w3)-y3_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x_train[:,j].reshape(tr,1)))\n",
        "    w3[j] = w3[j] - (1/tr)*0.1*jsum - ((0.1*0.05)/2)*np.sign(w3[j])\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.8125\n",
            "Class 2 Accuracy = 1.0\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcMI3LI1uTN"
      },
      "source": [
        "## SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FcTyudTwsLG"
      },
      "source": [
        "### LoR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pet6FVfrwsLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f873dc-6f90-4b2f-9959-196fedfb6a05"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w1)[index]-y1_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w1[j] = w1[j] - 0.3*j2\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w2)[index]-y2_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w2[j] = w2[j] - 0.7*j2\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w3)[index]-y3_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w3[j] = w3[j] - 0.7*j2\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  0.  2.]\n",
            " [ 1.  9.  0.]\n",
            " [ 0.  0. 16.]]\n",
            "Class 1 Accuracy = 0.875\n",
            "Class 2 Accuracy = 0.9\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnL8C4S21uTP"
      },
      "source": [
        "### LoR with L2 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yqhr4T01uTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12d3967-2a23-46e6-e480-a30bb5355597"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w1)[index]-y1_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w1[j] = (1-(0.0004*1.3))*w1[j] - 1.3*j2\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w2)[index]-y2_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w2[j] = (1-(0.0009*1.2))*w2[j] - 1.2*j2\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w3)[index]-y3_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w3[j] = (1-(0.008*2))*w3[j] - 2*j2\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.  1.  0.]\n",
            " [ 1. 11.  0.]\n",
            " [ 6.  0.  6.]]\n",
            "Class 1 Accuracy = 0.9444444444444444\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 0.5\n",
            "Overall Accuracy = 0.8095238095238095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYvIFCi7y2FT"
      },
      "source": [
        "### LoR with L1 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VvbYA8iy2FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf91de2-3cca-48de-a69b-7cc3c0317413"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w1)[index]-y1_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w1[j] = w1[j] - 1.5*j2 - ((1.5*0.0005)/2)*np.sign(w1[j])\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w2)[index]-y2_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w2[j] = w2[j] - 1.3*j2 - ((1.3*0.0005)/2)*np.sign(w2[j])\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(tr)\n",
        "  j1 = hyp_lor(x_train,w3)[index]-y3_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x_train[index,j].reshape(1,1))\n",
        "    w3[j] = w3[j] - 1.2*j2 - ((1.2*0.0005)/2)*np.sign(w3[j])\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16.  2.  0.]\n",
            " [ 1. 11.  0.]\n",
            " [ 4.  0.  8.]]\n",
            "Class 1 Accuracy = 0.8888888888888888\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 0.6666666666666666\n",
            "Overall Accuracy = 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joIVLX_ly2E8"
      },
      "source": [
        "## MBGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiEikG6qz6yU"
      },
      "source": [
        "### LoR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtHUTMvrz6yX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbae878-69ce-43d6-f9a5-b13becda75e3"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w1) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w1[j] = w1[j] - (1/15)*1.5*jsum\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w2) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+1].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w2[j] = w2[j] - (1/15)*0.7*jsum\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w3) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+2].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w3[j] = w3[j] - (1/15)*0.8*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  0.  2.]\n",
            " [ 1.  9.  0.]\n",
            " [ 0.  0. 16.]]\n",
            "Class 1 Accuracy = 0.875\n",
            "Class 2 Accuracy = 0.9\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8hcwD0H1uTR"
      },
      "source": [
        "### LoR with L2 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1XJ8YLa1uTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc7c9be-373a-43f2-d8b0-7ca4f0aca589"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1)\n",
        "for t in range(600):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w1) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w1[j] = (1-(0.001*0.2))*w1[j] - 0.2*jsum\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1)\n",
        "for t in range(600):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w2) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+1].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w2[j] = (1-(0.008*1))*w2[j] - 1*jsum\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1)\n",
        "for t in range(600):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w3) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+2].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w3[j] = (1-(0.008*0.01))*w3[j] - 0.01*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  4.  0.]\n",
            " [ 0. 12.  0.]\n",
            " [ 4.  0.  8.]]\n",
            "Class 1 Accuracy = 0.7777777777777778\n",
            "Class 2 Accuracy = 1.0\n",
            "Class 3 Accuracy = 0.6666666666666666\n",
            "Overall Accuracy = 0.8095238095238095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPW2PYQiy2FV"
      },
      "source": [
        "### LoR with L1 NORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKum62Cry2FV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8485f35b-4e85-49a4-fc29-1ca363403120"
      },
      "source": [
        "# 1 vs (2,3)\n",
        "\n",
        "w1=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w1) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w1[j] = w1[j] - (1/15)*1*jsum - ((1*0.05)/2)*np.sign(w1[j])\n",
        "\n",
        "# 2 vs (1,3)\n",
        "\n",
        "w2=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w2) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+1].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w2[j] = w2[j] - (1/15)*0.8*jsum - ((0.8*0.005)/2)*np.sign(w2[j])\n",
        "\n",
        "# 3 vs (1,2)\n",
        "\n",
        "w3=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(data_tr)\n",
        "  hypo1 = np.dot(data_tr[:15,:f].reshape(15,f),w3) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,data_tr[:15,f+2].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,data_tr[:15,j].reshape(15,1)))\n",
        "    w3[j] = w3[j] - (1/15)*0.5*jsum - ((0.5*0.005)/2)*np.sign(w3[j])\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w1),hyp_lor(x_test,w2),hyp_lor(x_test,w3)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  class_def=np.argmax(y_pred[i])\n",
        "  output[i]=class_def+1\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13.  1.  2.]\n",
            " [ 0. 10.  0.]\n",
            " [ 0.  0. 16.]]\n",
            "Class 1 Accuracy = 0.8125\n",
            "Class 2 Accuracy = 1.0\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISdK05wzgTf"
      },
      "source": [
        "# one vs one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izJAFg8KPhyz"
      },
      "source": [
        "### data splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJkqiZvRPhy9"
      },
      "source": [
        "data=np.array(data); np.random.shuffle(data);np.random.shuffle(data)\n",
        "x_train = data[:147,:].copy() ; y_train = data[:147,-1].copy()\n",
        "norm = np.amax(np.abs(x_train[:,:f]),axis=0)\n",
        "x_test = data[147:189,:f].copy()/norm ; y_test = data[147:189,-1].copy().reshape(42,1) ; te=42\n",
        "class_1 = x_train[np.where(y_train==1)]\n",
        "class_2 = x_train[np.where(y_train==2)]\n",
        "class_3 = x_train[np.where(y_train==3)]\n",
        "train12 = np.concatenate((class_1,class_2),axis=0) ; np.random.shuffle(train12)\n",
        "train23 = np.concatenate((class_2,class_3),axis=0) ; np.random.shuffle(train23)\n",
        "train31 = np.concatenate((class_3,class_1),axis=0) ; np.random.shuffle(train31)\n",
        "y12_train = train12[:,f].reshape(len(train12[:,f]),1)\n",
        "y23_train = train23[:,f+1].reshape(len(train23[:,f+1]),1)\n",
        "y31_train = train31[:,f+2].reshape(len(train31[:,f+2]),1)\n",
        "x12_train = train12[:,:f].copy()/norm\n",
        "x23_train = train23[:,:f].copy()/norm\n",
        "x31_train = train31[:,:f].copy()/norm\n",
        "norm_mb = list(norm) ; norm_mb = norm_mb+[1,1,1,1] ; norm_mb = np.array(norm_mb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQXWECF3SaLl"
      },
      "source": [
        "## LoR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXDcHs0SSaLt"
      },
      "source": [
        "### BGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9CD_bbZSaLt",
        "outputId": "155b05e0-49c8-478b-82f3-9e5626f8e64b"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x12_train,w12)-y12_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x12_train[:,j].reshape(len(y12_train),1)))\n",
        "    w12[j] = w12[j] - (1/len(y12_train))*0.3*jsum\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x23_train,w23)-y23_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x23_train[:,j].reshape(len(y23_train),1)))\n",
        "    w23[j] = w23[j] - (1/len(y23_train))*0.3*jsum\n",
        "\n",
        "# 3 vs 1\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x31_train,w31)-y31_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x31_train[:,j].reshape(len(y31_train),1)))\n",
        "    w31[j] = w31[j] - (1/len(y31_train))*0.8*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.8461538461538461\n",
            "Class 2 Accuracy = 1.0\n",
            "Class 3 Accuracy = 0.9333333333333333\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmI8-xFSaLu"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnjNbkVFSaLu",
        "outputId": "f0f5b824-7d1f-45c3-89d2-e0fffe691e44"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(len(y12_train))\n",
        "  j1 = hyp_lor(x12_train,w12)[index]-y12_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x12_train[index,j].reshape(1,1))\n",
        "    w12[j] = w12[j] - 0.3*j2\n",
        "\n",
        "# 2 vs 1\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(len(y23_train))\n",
        "  j1 = hyp_lor(x23_train,w23)[index]-y23_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x23_train[index,j].reshape(1,1))\n",
        "    w23[j] = w23[j] - 0.7*j2\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(len(y31_train))\n",
        "  j1 = hyp_lor(x31_train,w31)[index]-y31_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x31_train[index,j].reshape(1,1))\n",
        "    w31[j] = w31[j] - 0.7*j2\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  1.  0.]\n",
            " [ 1. 11.  0.]\n",
            " [ 1.  0. 14.]]\n",
            "Class 1 Accuracy = 0.9333333333333333\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 0.9333333333333333\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDXJ1OPCSaLv"
      },
      "source": [
        "### MBGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m5HH6GkSaLv",
        "outputId": "a8868f7f-0eee-4f8f-8117-687972ced6aa"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train12)\n",
        "  tr12 = train12/norm_mb\n",
        "  hypo1 = np.dot(tr12[:15,:f].reshape(15,f),w12) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr12[:15,f].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr12[:15,j].reshape(15,1)))\n",
        "    w12[j] = w12[j] - (1/15)*0.6*jsum\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train23)\n",
        "  tr23 = train23/norm_mb\n",
        "  hypo1 = np.dot(tr23[:15,:f].reshape(15,f),w23) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr23[:15,f+1].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr23[:15,j].reshape(15,1)))\n",
        "    w23[j] = w23[j] - (1/15)*0.7*jsum\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train31)\n",
        "  tr31 = train31/norm_mb\n",
        "  hypo1 = np.dot(tr31[:15,:f].reshape(15,f),w31) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr31[:15,f+2].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr31[:15,j].reshape(15,1)))\n",
        "    w31[j] = w31[j] - (1/15)*0.8*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  1.  0.]\n",
            " [ 1. 11.  0.]\n",
            " [ 0.  0. 15.]]\n",
            "Class 1 Accuracy = 0.9333333333333333\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li2T3CcfW734"
      },
      "source": [
        "## LoR with L2 NORM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GD4oqo3W73_"
      },
      "source": [
        "### BGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcDo8OqXW74A",
        "outputId": "8bf203f6-54a1-47e9-9efc-142c53c3cc8d"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x12_train,w12)-y12_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x12_train[:,j].reshape(len(y12_train),1)))\n",
        "    w12[j] = (1-(0.001*2))*w12[j] - (1/len(y12_train))*2*jsum\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x23_train,w23)-y23_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x23_train[:,j].reshape(len(y23_train),1)))\n",
        "    w23[j] = (1-(0.002*1))*w23[j] - (1/len(y23_train))*1*jsum\n",
        "\n",
        "# 3 vs 1\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x31_train,w31)-y31_train # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x31_train[:,j].reshape(len(y31_train),1)))\n",
        "    w31[j] = (1-(0.002*1))*w31[j] - (1/len(y31_train))*1*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.8571428571428571\n",
            "Class 2 Accuracy = 0.9090909090909091\n",
            "Class 3 Accuracy = 0.9411764705882353\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiD43tOZW74B"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "536QT8qkW74B",
        "outputId": "58a4c222-5cef-4695-fd60-df9b3981ea66"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(600):\n",
        "  index=np.random.randint(len(y12_train))\n",
        "  j1 = hyp_lor(x12_train,w12)[index]-y12_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x12_train[index,j].reshape(1,1))\n",
        "    w12[j] = (1-(0.0001*1))*w12[j] - 1*j2\n",
        "\n",
        "# 2 vs 1\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(len(y23_train))\n",
        "  j1 = hyp_lor(x23_train,w23)[index]-y23_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x23_train[index,j].reshape(1,1))\n",
        "    w23[j] = (1-(0.0001*1))*w23[j] - 1*j2\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  index=np.random.randint(len(y31_train))\n",
        "  j1 = hyp_lor(x31_train,w31)[index]-y31_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x31_train[index,j].reshape(1,1))\n",
        "    w31[j] = (1-(0.0001*1))*w31[j] - 1*j2\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13.  0.  1.]\n",
            " [ 2.  9.  0.]\n",
            " [ 1.  0. 16.]]\n",
            "Class 1 Accuracy = 0.9285714285714286\n",
            "Class 2 Accuracy = 0.8181818181818182\n",
            "Class 3 Accuracy = 0.9411764705882353\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOqJk2eWW74B"
      },
      "source": [
        "### MBGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVoLxgQxW74B",
        "outputId": "a6bb6f5a-40d8-4b80-c525-4dd628afb373"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train12)\n",
        "  tr12 = train12/norm_mb\n",
        "  hypo1 = np.dot(tr12[:5,:f].reshape(5,f),w12) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr12[:5,f].reshape(5,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr12[:5,j].reshape(5,1)))\n",
        "    w12[j] = (1-(0.002*1))*w12[j] - (1/5)*1*jsum\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train23)\n",
        "  tr23 = train23/norm_mb\n",
        "  hypo1 = np.dot(tr23[:5,:f].reshape(5,f),w23) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr23[:5,f+1].reshape(5,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr23[:5,j].reshape(5,1)))\n",
        "    w23[j] = (1-(0.002*1))*w23[j] - (1/5)*1*jsum\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train31)\n",
        "  tr31 = train31/norm_mb\n",
        "  hypo1 = np.dot(tr31[:5,:f].reshape(5,f),w31) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr31[:5,f+2].reshape(5,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr31[:5,j].reshape(5,1)))\n",
        "    w31[j] = (1-(0.002*1))*w31[j] - (1/5)*1*jsum\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9.  1.  2.]\n",
            " [ 0. 22.  0.]\n",
            " [ 1.  0.  7.]]\n",
            "Class 1 Accuracy = 0.75\n",
            "Class 2 Accuracy = 1.0\n",
            "Class 3 Accuracy = 0.875\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BL4VknVW89v"
      },
      "source": [
        "## LoR with L1 NORM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEK8qtUW89v"
      },
      "source": [
        "### BGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEpv4UVwW89w",
        "outputId": "a15e5e18-485c-49be-edaf-bd8a6331ccac"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x12_train,w12)-y12_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x12_train[:,j].reshape(len(y12_train),1)))\n",
        "    w12[j] = w12[j] - (1/len(y12_train))*2*jsum - ((2*0.0005)/2)*np.sign(w12[j])\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x23_train,w23)-y23_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x23_train[:,j].reshape(len(y23_train),1)))\n",
        "    w23[j] = w23[j] - (1/len(y23_train))*0.3*jsum - ((0.3*0.005)/2)*np.sign(w23[j])\n",
        "\n",
        "# 3 vs 1\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(500):\n",
        "  j1 = hyp_lor(x31_train,w31)-y31_train, # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,x31_train[:,j].reshape(len(y31_train),1)))\n",
        "    w31[j] = w31[j] - (1/len(y31_train))*0.8*jsum - ((0.8*0.005)/2)*np.sign(w31[j])\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy = 0.875\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib30kSVvW89w"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_3_3OVdW89w",
        "outputId": "eba56b75-08ea-41f0-c556-425f8e91f795"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(len(y12_train))\n",
        "  j1 = hyp_lor(x12_train,w12)[index]-y12_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x12_train[index,j].reshape(1,1))\n",
        "    w12[j] = w12[j] - 0.7*j2 - ((0.7*0.005)/2)*np.sign(w12[j])\n",
        "\n",
        "# 2 vs 1\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(len(y23_train))\n",
        "  j1 = hyp_lor(x23_train,w23)[index]-y23_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x23_train[index,j].reshape(1,1))\n",
        "    w23[j] = w23[j] - 0.7*j2 - ((0.7*0.0005)/2)*np.sign(w23[j])\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1) # weight vector initialised\n",
        "for t in range(1000):\n",
        "  index=np.random.randint(len(y31_train))\n",
        "  j1 = hyp_lor(x31_train,w31)[index]-y31_train[index] # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    j2 = np.multiply(j1,x31_train[index,j].reshape(1,1))\n",
        "    w31[j] = w31[j] - 0.7*j2 - ((0.7*0.005)/2)*np.sign(w31[j])\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15.  0.  1.]\n",
            " [ 3.  9.  0.]\n",
            " [ 0.  0. 14.]]\n",
            "Class 1 Accuracy = 0.9375\n",
            "Class 2 Accuracy = 0.75\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ufi4XqrW89x"
      },
      "source": [
        "### MBGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sE6M3Y7W89x",
        "outputId": "a6bc1d92-3157-4791-bba1-3ffb6575daae"
      },
      "source": [
        "# 1 vs 2\n",
        "\n",
        "w12=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train12)\n",
        "  tr12 = train12/norm_mb\n",
        "  hypo1 = np.dot(tr12[:15,:f].reshape(15,f),w12) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr12[:15,f].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr12[:15,j].reshape(15,1)))\n",
        "    w12[j] = w12[j] - (1/15)*0.6*jsum - ((0.6*0.005)/2)*np.sign(w12[j])\n",
        "\n",
        "# 2 vs 3\n",
        "\n",
        "w23=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train23)\n",
        "  tr23 = train23/norm_mb\n",
        "  hypo1 = np.dot(tr23[:15,:f].reshape(15,f),w23) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr23[:15,f+1].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr23[:15,j].reshape(15,1)))\n",
        "    w23[j] = w23[j] - (1/15)*0.7*jsum - ((0.7*0.0025)/2)*np.sign(w23[j])\n",
        "\n",
        "# 3 vs 1\n",
        "\n",
        "w31=np.random.rand(f).reshape(f,1)\n",
        "for t in range(450):\n",
        "  np.random.shuffle(train31)\n",
        "  tr31 = train31/norm_mb\n",
        "  hypo1 = np.dot(tr31[:15,:f].reshape(15,f),w31) # hypothesis array part1\n",
        "  hypo = 1/(1+np.exp(-hypo1))\n",
        "  j1 = np.subtract(hypo,tr31[:15,f+2].reshape(15,1)) # (hyp(xi)-yi)\n",
        "  for j in range(f):\n",
        "    jsum = np.sum(np.multiply(j1,tr31[:15,j].reshape(15,1)))\n",
        "    w31[j] = w31[j] - (1/15)*0.8*jsum - ((0.8*0.005)/2)*np.sign(w31[j])\n",
        "\n",
        "# testing\n",
        "\n",
        "y_pred=np.concatenate((hyp_lor(x_test,w12),hyp_lor(x_test,w23),hyp_lor(x_test,w31)),axis=1)\n",
        "output=np.zeros((te,1))\n",
        "\n",
        "for i in range(te):\n",
        "  y_pred[i][0] = 1 if (y_pred[i][0]>0.5) else 2\n",
        "  y_pred[i][1] = 2 if (y_pred[i][1]>0.5) else 3\n",
        "  y_pred[i][2] = 3 if (y_pred[i][2]>0.5) else 1\n",
        "  class_def=stats.mode(y_pred[i])\n",
        "  output[i]=class_def[0]\n",
        "\n",
        "comparison=np.concatenate((output,y_test),axis=1)\n",
        "\n",
        "# performance evaluation\n",
        "\n",
        "conf_matrix=np.zeros((3,3)) # confusion matrix\n",
        "for comp in comparison:\n",
        "  pred,act=int(comp[0]-1),int(comp[1]-1)\n",
        "  conf_matrix[act][pred]+=1\n",
        "print(conf_matrix)\n",
        "\n",
        "cm,o_num,o_den=conf_matrix,0,0\n",
        "for i in range(3):\n",
        "  den=0\n",
        "  for j in range(3):\n",
        "    den=den+cm[i][j]\n",
        "  acc=cm[i][i]/den\n",
        "  print('Class {} Accuracy = {}'.format(i+1,acc))\n",
        "  o_num=o_num+cm[i][i]\n",
        "  o_den=o_den+den\n",
        "\n",
        "print('Overall Accuracy = {}'.format(o_num/o_den))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14.  0.  2.]\n",
            " [ 1. 11.  0.]\n",
            " [ 0.  0. 14.]]\n",
            "Class 1 Accuracy = 0.875\n",
            "Class 2 Accuracy = 0.9166666666666666\n",
            "Class 3 Accuracy = 1.0\n",
            "Overall Accuracy = 0.9285714285714286\n"
          ]
        }
      ]
    }
  ]
}